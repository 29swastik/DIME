{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2796da7a",
   "metadata": {},
   "source": [
    "# DIME Implementation: PRF and LLM-based Dimension Importance Estimation\n",
    "\n",
    "This notebook implements the two main approaches from the DIME paper:\n",
    "1. **PRF-based approach**: Uses Pseudo-Relevance Feedback to compute centroids and determine dimension importance\n",
    "2. **LLM-based approach**: Uses LLM-generated documents to determine dimension importance\n",
    "\n",
    "Each approach supports both:\n",
    "- **Rerank**: Re-score existing retrieval results with modified query vectors\n",
    "- **Refetch**: Perform new retrieval with modified query vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32fb172a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnamursw/personal/dime/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed7d7976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 125/125 [00:24<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product embeddings shape: (2000, 384)\n",
      "Sample embedding: [-0.03355468 -0.01013993  0.05335136 -0.03003556  0.01181867]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data and model\n",
    "df = pd.read_csv('/home/krishnamursw/personal/dime/apparel_dataset.csv')\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for all products\n",
    "print(\"Generating embeddings...\")\n",
    "product_embeddings = model.encode(\n",
    "    df['text'].tolist(), \n",
    "    batch_size=16, \n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True  # Normalize for dot product similarity\n",
    ")\n",
    "\n",
    "print(f\"Product embeddings shape: {product_embeddings.shape}\")\n",
    "print(f\"Sample embedding: {product_embeddings[0][:5]}\")  # First 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea675647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Utility functions from query.py\n",
    "def normalize_scores(arr, t_min=0, t_max=1):\n",
    "    \"\"\"Normalize array values to [t_min, t_max] range\"\"\"\n",
    "    diff = t_max - t_min\n",
    "    arr_min = np.min(arr)\n",
    "    arr_max = np.max(arr)\n",
    "    if arr_max == arr_min:\n",
    "        return np.full_like(arr, (t_min + t_max) / 2)\n",
    "    norm_arr = (((arr - arr_min) * diff) / (arr_max - arr_min)) + t_min\n",
    "    return norm_arr\n",
    "\n",
    "def softmax(scores, temperature=1.0):\n",
    "    \"\"\"Compute softmax over an array of scores with optional temperature\"\"\"\n",
    "    scaled_scores = scores / temperature\n",
    "    exps = np.exp(scaled_scores - np.max(scaled_scores))\n",
    "    return exps / np.sum(exps)\n",
    "\n",
    "def compute_centroid(embeddings, scores, k=None, weighted=False, attention_type=\"linear\", temperature=1.0):\n",
    "    \"\"\"\n",
    "    Compute the centroid of the top-k embeddings with optional weighting\n",
    "    \n",
    "    Args:\n",
    "        embeddings: Array of embeddings\n",
    "        scores: Array of scores corresponding to embeddings\n",
    "        k: Number of top embeddings to use (None = use all)\n",
    "        weighted: Whether to use weighted average\n",
    "        attention_type: Type of attention (\"linear\" or \"softmax\")\n",
    "        temperature: Temperature for softmax attention\n",
    "        \n",
    "    Returns:\n",
    "        Centroid vector\n",
    "    \"\"\"\n",
    "    if k is not None and k > 0:\n",
    "        # Sort by scores (descending) and take top-k\n",
    "        sorted_indices = np.argsort(scores)[::-1][:k]\n",
    "        embeddings = embeddings[sorted_indices]\n",
    "        scores = scores[sorted_indices]\n",
    "    \n",
    "    if weighted:\n",
    "        if attention_type == \"linear\":\n",
    "            weights = normalize_scores(scores, 0, 1)\n",
    "        else:  # \"softmax\"\n",
    "            weights = softmax(scores, temperature)\n",
    "        centroid = np.average(embeddings, axis=0, weights=weights)\n",
    "    else:\n",
    "        centroid = np.mean(embeddings, axis=0)\n",
    "    \n",
    "    return centroid\n",
    "\n",
    "def zero_out_least_important_dims(centroid, query_vector, alpha=0.8):\n",
    "    \"\"\"\n",
    "    Zero out the lowest (1-alpha) fraction of dimensions in query_vector\n",
    "    based on element-wise product between centroid and query_vector\n",
    "    \n",
    "    Args:\n",
    "        centroid: Centroid vector for dimension importance\n",
    "        query_vector: Original query vector\n",
    "        alpha: Fraction of dimensions to keep (0.8 means keep 80%)\n",
    "        \n",
    "    Returns:\n",
    "        Modified query vector with least important dimensions zeroed out\n",
    "    \"\"\"\n",
    "    # Element-wise product to determine dimension importance\n",
    "    importance_vec = np.multiply(centroid, query_vector)\n",
    "    dim = len(importance_vec)\n",
    "    keep_count = int(alpha * dim)\n",
    "    \n",
    "    if keep_count >= dim:\n",
    "        return query_vector.copy()\n",
    "    \n",
    "    # Get indices of most important dimensions\n",
    "    sorted_indices = np.argsort(importance_vec)\n",
    "    keep_indices = set(sorted_indices[-keep_count:])\n",
    "    \n",
    "    # Zero out least important dimensions\n",
    "    modified_query_vector = query_vector.copy()\n",
    "    for i in range(dim):\n",
    "        if i not in keep_indices:\n",
    "            modified_query_vector[i] = 0.0\n",
    "    \n",
    "    return modified_query_vector\n",
    "\n",
    "def basic_search(query, top_k=10):\n",
    "    \"\"\"Basic search function for initial retrieval\"\"\"\n",
    "    query_embedding = model.encode([query], normalize_embeddings=True)[0]\n",
    "    scores = np.dot(product_embeddings, query_embedding)\n",
    "    top_indices = np.argsort(scores)[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        results.append({\n",
    "            'rank': i + 1,\n",
    "            'index': idx,\n",
    "            'product_id': df.iloc[idx]['product_id'],\n",
    "            'title': df.iloc[idx]['title'],\n",
    "            'score': scores[idx],\n",
    "            'embedding': product_embeddings[idx]\n",
    "        })\n",
    "    \n",
    "    return results, query_embedding\n",
    "\n",
    "print(\"Utility functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fba379",
   "metadata": {},
   "source": [
    "## 1. PRF-based Approach\n",
    "\n",
    "This approach uses Pseudo-Relevance Feedback to compute centroids from initially retrieved documents and determine dimension importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1a2bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRF-based DIME initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "class PRFBasedDIME:\n",
    "    \"\"\"\n",
    "    PRF-based Dimension Importance Estimation for Dense Retrieval\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, embeddings, dataframe):\n",
    "        self.model = model\n",
    "        self.embeddings = embeddings\n",
    "        self.df = dataframe\n",
    "        \n",
    "    def prf_rerank(self, query, initial_top_k=1000, prf_k=10, final_top_k=10, \n",
    "                   zero_out_ratio=0.2, weighted=False, attention_type=\"linear\", temperature=1.0):\n",
    "        \"\"\"\n",
    "        PRF-based reranking: modify query vector and re-score existing results\n",
    "        \n",
    "        Args:\n",
    "            query: Search query text\n",
    "            initial_top_k: Number of documents to retrieve initially\n",
    "            prf_k: Number of top documents to use for PRF\n",
    "            final_top_k: Number of final results to return\n",
    "            zero_out_ratio: Fraction of dimensions to zero out (0.2 means zero out 20%)\n",
    "            weighted: Whether to use weighted centroid\n",
    "            attention_type: Type of attention weighting\n",
    "            temperature: Temperature for softmax\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with original and reranked results\n",
    "        \"\"\"\n",
    "        # Step 1: Initial retrieval\n",
    "        print(f\"Step 1: Initial retrieval (top-{initial_top_k})...\")\n",
    "        initial_results, original_query_embedding = basic_search(query, initial_top_k)\n",
    "        \n",
    "        # Step 2: Compute centroid from top-k PRF documents\n",
    "        print(f\"Step 2: Computing centroid from top-{prf_k} PRF documents...\")\n",
    "        prf_embeddings = np.array([r['embedding'] for r in initial_results[:prf_k]])\n",
    "        prf_scores = np.array([r['score'] for r in initial_results[:prf_k]])\n",
    "        \n",
    "        centroid = compute_centroid(prf_embeddings, prf_scores, k=None, \n",
    "                                  weighted=weighted, attention_type=attention_type, \n",
    "                                  temperature=temperature)\n",
    "        \n",
    "        # Step 3: Zero out least important dimensions\n",
    "        print(f\"Step 3: Zeroing out {zero_out_ratio*100}% least important dimensions...\")\n",
    "        alpha = 1 - zero_out_ratio\n",
    "        modified_query_embedding = zero_out_least_important_dims(centroid, original_query_embedding, alpha)\n",
    "        \n",
    "        # Step 4: Re-score all initial results with modified query\n",
    "        print(f\"Step 4: Re-scoring with modified query...\")\n",
    "        reranked_results = []\n",
    "        for result in initial_results:\n",
    "            new_score = float(np.dot(modified_query_embedding, result['embedding']))\n",
    "            reranked_results.append({\n",
    "                'rank': result['rank'],\n",
    "                'index': result['index'],\n",
    "                'product_id': result['product_id'],\n",
    "                'title': result['title'],\n",
    "                'original_score': result['score'],\n",
    "                'new_score': new_score\n",
    "            })\n",
    "        \n",
    "        # Sort by new scores and take top-k\n",
    "        reranked_results.sort(key=lambda x: -x['new_score'])\n",
    "        final_results = reranked_results[:final_top_k]\n",
    "        \n",
    "        # Update ranks\n",
    "        for i, result in enumerate(final_results):\n",
    "            result['rank'] = i + 1\n",
    "        \n",
    "        return {\n",
    "            'method': 'prf_rerank',\n",
    "            'query': query,\n",
    "            'prf_k': prf_k,\n",
    "            'zero_out_ratio': zero_out_ratio,\n",
    "            'weighted': weighted,\n",
    "            'attention_type': attention_type,\n",
    "            'original_results': initial_results[:final_top_k],\n",
    "            'reranked_results': final_results,\n",
    "            'centroid': centroid,\n",
    "            'original_query_embedding': original_query_embedding,\n",
    "            'modified_query_embedding': modified_query_embedding\n",
    "        }\n",
    "    \n",
    "    def prf_refetch(self, query, initial_top_k=1000, prf_k=10, final_top_k=10, \n",
    "                    zero_out_ratio=0.2, weighted=False, attention_type=\"linear\", temperature=1.0):\n",
    "        \"\"\"\n",
    "        PRF-based refetching: modify query vector and perform new retrieval\n",
    "        \n",
    "        Args:\n",
    "            query: Search query text\n",
    "            initial_top_k: Number of documents to retrieve initially for PRF\n",
    "            prf_k: Number of top documents to use for PRF\n",
    "            final_top_k: Number of final results to return after refetch\n",
    "            zero_out_ratio: Fraction of dimensions to zero out\n",
    "            weighted: Whether to use weighted centroid\n",
    "            attention_type: Type of attention weighting\n",
    "            temperature: Temperature for softmax\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with original and refetched results\n",
    "        \"\"\"\n",
    "        # Step 1: Initial retrieval for PRF\n",
    "        print(f\"Step 1: Initial retrieval for PRF (top-{initial_top_k})...\")\n",
    "        initial_results, original_query_embedding = basic_search(query, initial_top_k)\n",
    "        \n",
    "        # Step 2: Compute centroid from top-k PRF documents\n",
    "        print(f\"Step 2: Computing centroid from top-{prf_k} PRF documents...\")\n",
    "        prf_embeddings = np.array([r['embedding'] for r in initial_results[:prf_k]])\n",
    "        prf_scores = np.array([r['score'] for r in initial_results[:prf_k]])\n",
    "        \n",
    "        centroid = compute_centroid(prf_embeddings, prf_scores, k=None, \n",
    "                                  weighted=weighted, attention_type=attention_type, \n",
    "                                  temperature=temperature)\n",
    "        \n",
    "        # Step 3: Zero out least important dimensions\n",
    "        print(f\"Step 3: Zeroing out {zero_out_ratio*100}% least important dimensions...\")\n",
    "        alpha = 1 - zero_out_ratio\n",
    "        modified_query_embedding = zero_out_least_important_dims(centroid, original_query_embedding, alpha)\n",
    "        \n",
    "        # Step 4: Perform new retrieval with modified query\n",
    "        print(f\"Step 4: Performing new retrieval with modified query...\")\n",
    "        refetch_scores = np.dot(self.embeddings, modified_query_embedding)\n",
    "        top_indices = np.argsort(refetch_scores)[::-1][:final_top_k]\n",
    "        \n",
    "        refetched_results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            refetched_results.append({\n",
    "                'rank': i + 1,\n",
    "                'index': idx,\n",
    "                'product_id': self.df.iloc[idx]['product_id'],\n",
    "                'title': self.df.iloc[idx]['title'],\n",
    "                'score': refetch_scores[idx]\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'method': 'prf_refetch',\n",
    "            'query': query,\n",
    "            'prf_k': prf_k,\n",
    "            'zero_out_ratio': zero_out_ratio,\n",
    "            'weighted': weighted,\n",
    "            'attention_type': attention_type,\n",
    "            'original_results': initial_results[:final_top_k],\n",
    "            'refetched_results': refetched_results,\n",
    "            'centroid': centroid,\n",
    "            'original_query_embedding': original_query_embedding,\n",
    "            'modified_query_embedding': modified_query_embedding\n",
    "        }\n",
    "\n",
    "# Initialize PRF-based DIME\n",
    "prf_dime = PRFBasedDIME(model, product_embeddings, df)\n",
    "print(\"PRF-based DIME initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4fe9f",
   "metadata": {},
   "source": [
    "## 2. LLM-based Approach\n",
    "\n",
    "This approach uses LLM-generated documents to determine dimension importance directly without requiring initial retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16573c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-based DIME initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "class LLMBasedDIME:\n",
    "    \"\"\"\n",
    "    LLM-based Dimension Importance Estimation for Dense Retrieval\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, embeddings, dataframe):\n",
    "        self.model = model\n",
    "        self.embeddings = embeddings\n",
    "        self.df = dataframe\n",
    "        \n",
    "    def generate_llm_doc(self, query):\n",
    "        \"\"\"\n",
    "        Generate LLM-style document for the query\n",
    "        Since we don't have actual LLM, we'll simulate by creating expanded query\n",
    "        \"\"\"\n",
    "        # Simple expansion - in real implementation, this would use an LLM\n",
    "        expanded_queries = {\n",
    "            \"black dress shirt\": \"elegant black dress shirt formal business professional men's clothing cotton long sleeve button up office wear\",\n",
    "            \"blue jeans\": \"blue denim jeans casual wear pants trousers men women comfortable cotton everyday fashion\",\n",
    "            \"white sneakers\": \"white athletic sneakers shoes casual sports footwear comfortable rubber sole walking running\",\n",
    "            \"red dress\": \"red dress women's formal elegant party evening wear special occasion outfit stylish\",\n",
    "            \"brown leather boots\": \"brown leather boots shoes footwear men's outdoor durable sturdy walking hiking\",\n",
    "            \"casual t-shirt\": \"casual t-shirt comfortable cotton everyday wear men women basic wardrobe essential\",\n",
    "            \"winter coat\": \"winter coat warm jacket outerwear cold weather protection insulated heavy duty\",\n",
    "            \"summer dress\": \"summer dress light breathable women's warm weather casual comfortable seasonal clothing\"\n",
    "        }\n",
    "        \n",
    "        # Find best match or use original query\n",
    "        best_match = query.lower()\n",
    "        for key in expanded_queries:\n",
    "            if key in query.lower():\n",
    "                best_match = key\n",
    "                break\n",
    "        \n",
    "        return expanded_queries.get(best_match, f\"clothing apparel fashion {query} style comfortable quality\")\n",
    "    \n",
    "    def llm_rerank(self, query, initial_top_k=1000, final_top_k=10, zero_out_ratio=0.2):\n",
    "        \"\"\"\n",
    "        LLM-based reranking: use LLM-generated doc to modify query vector and re-score\n",
    "        \n",
    "        Args:\n",
    "            query: Search query text\n",
    "            initial_top_k: Number of documents to retrieve initially\n",
    "            final_top_k: Number of final results to return\n",
    "            zero_out_ratio: Fraction of dimensions to zero out\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with original and reranked results\n",
    "        \"\"\"\n",
    "        # Step 1: Initial retrieval\n",
    "        print(f\"Step 1: Initial retrieval (top-{initial_top_k})...\")\n",
    "        initial_results, original_query_embedding = basic_search(query, initial_top_k)\n",
    "        \n",
    "        # Step 2: Generate LLM document and embed it\n",
    "        print(f\"Step 2: Generating and embedding LLM document...\")\n",
    "        llm_doc = self.generate_llm_doc(query)\n",
    "        print(f\"Generated LLM doc: {llm_doc}\")\n",
    "        llm_embedding = self.model.encode([llm_doc], normalize_embeddings=True)[0]\n",
    "        \n",
    "        # Step 3: Zero out least important dimensions using LLM embedding\n",
    "        print(f\"Step 3: Zeroing out {zero_out_ratio*100}% least important dimensions...\")\n",
    "        alpha = 1 - zero_out_ratio\n",
    "        modified_query_embedding = zero_out_least_important_dims(llm_embedding, original_query_embedding, alpha)\n",
    "        \n",
    "        # Step 4: Re-score all initial results with modified query\n",
    "        print(f\"Step 4: Re-scoring with modified query...\")\n",
    "        reranked_results = []\n",
    "        for result in initial_results:\n",
    "            new_score = float(np.dot(modified_query_embedding, result['embedding']))\n",
    "            reranked_results.append({\n",
    "                'rank': result['rank'],\n",
    "                'index': result['index'],\n",
    "                'product_id': result['product_id'],\n",
    "                'title': result['title'],\n",
    "                'original_score': result['score'],\n",
    "                'new_score': new_score\n",
    "            })\n",
    "        \n",
    "        # Sort by new scores and take top-k\n",
    "        reranked_results.sort(key=lambda x: -x['new_score'])\n",
    "        final_results = reranked_results[:final_top_k]\n",
    "        \n",
    "        # Update ranks\n",
    "        for i, result in enumerate(final_results):\n",
    "            result['rank'] = i + 1\n",
    "        \n",
    "        return {\n",
    "            'method': 'llm_rerank',\n",
    "            'query': query,\n",
    "            'llm_doc': llm_doc,\n",
    "            'zero_out_ratio': zero_out_ratio,\n",
    "            'original_results': initial_results[:final_top_k],\n",
    "            'reranked_results': final_results,\n",
    "            'llm_embedding': llm_embedding,\n",
    "            'original_query_embedding': original_query_embedding,\n",
    "            'modified_query_embedding': modified_query_embedding\n",
    "        }\n",
    "    \n",
    "    def llm_refetch(self, query, final_top_k=10, zero_out_ratio=0.2):\n",
    "        \"\"\"\n",
    "        LLM-based refetching: use LLM-generated doc to modify query vector and perform new retrieval\n",
    "        \n",
    "        Args:\n",
    "            query: Search query text\n",
    "            final_top_k: Number of final results to return after refetch\n",
    "            zero_out_ratio: Fraction of dimensions to zero out\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with original and refetched results\n",
    "        \"\"\"\n",
    "        # Step 1: Get original query embedding and initial results for comparison\n",
    "        print(f\"Step 1: Getting original query embedding...\")\n",
    "        original_results, original_query_embedding = basic_search(query, final_top_k)\n",
    "        \n",
    "        # Step 2: Generate LLM document and embed it\n",
    "        print(f\"Step 2: Generating and embedding LLM document...\")\n",
    "        llm_doc = self.generate_llm_doc(query)\n",
    "        print(f\"Generated LLM doc: {llm_doc}\")\n",
    "        llm_embedding = self.model.encode([llm_doc], normalize_embeddings=True)[0]\n",
    "        \n",
    "        # Step 3: Zero out least important dimensions using LLM embedding\n",
    "        print(f\"Step 3: Zeroing out {zero_out_ratio*100}% least important dimensions...\")\n",
    "        alpha = 1 - zero_out_ratio\n",
    "        modified_query_embedding = zero_out_least_important_dims(llm_embedding, original_query_embedding, alpha)\n",
    "        \n",
    "        # Step 4: Perform new retrieval with modified query\n",
    "        print(f\"Step 4: Performing new retrieval with modified query...\")\n",
    "        refetch_scores = np.dot(self.embeddings, modified_query_embedding)\n",
    "        top_indices = np.argsort(refetch_scores)[::-1][:final_top_k]\n",
    "        \n",
    "        refetched_results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            refetched_results.append({\n",
    "                'rank': i + 1,\n",
    "                'index': idx,\n",
    "                'product_id': self.df.iloc[idx]['product_id'],\n",
    "                'title': self.df.iloc[idx]['title'],\n",
    "                'score': refetch_scores[idx]\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'method': 'llm_refetch',\n",
    "            'query': query,\n",
    "            'llm_doc': llm_doc,\n",
    "            'zero_out_ratio': zero_out_ratio,\n",
    "            'original_results': original_results,\n",
    "            'refetched_results': refetched_results,\n",
    "            'llm_embedding': llm_embedding,\n",
    "            'original_query_embedding': original_query_embedding,\n",
    "            'modified_query_embedding': modified_query_embedding\n",
    "        }\n",
    "\n",
    "# Initialize LLM-based DIME\n",
    "llm_dime = LLMBasedDIME(model, product_embeddings, df)\n",
    "print(\"LLM-based DIME initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bec5b0",
   "metadata": {},
   "source": [
    "## 2.5. Magnitude-based Approach\n",
    "\n",
    "This approach uses the magnitude (absolute value) of query dimensions to determine importance. The assumption is that larger magnitude dimensions are more important, while smaller magnitude dimensions represent noise or less relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40668ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MagnitudeBasedDIME:\n",
    "    \"\"\"\n",
    "    Magnitude-based Dimension Importance Estimation for Dense Retrieval\n",
    "    Uses |qi| to determine dimension importance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, embeddings, dataframe):\n",
    "        self.model = model\n",
    "        self.embeddings = embeddings\n",
    "        self.df = dataframe\n",
    "        \n",
    "    def magnitude_rerank(self, query, initial_top_k=1000, final_top_k=10, zero_out_ratio=0.2):\n",
    "        \"\"\"\n",
    "        Magnitude-based reranking: use query magnitude to determine importance and re-score\n",
    "        \n",
    "        Args:\n",
    "            query: Search query text\n",
    "            initial_top_k: Number of documents to retrieve initially\n",
    "            final_top_k: Number of final results to return\n",
    "            zero_out_ratio: Fraction of dimensions to zero out\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with original and reranked results\n",
    "        \"\"\"\n",
    "        # Step 1: Initial retrieval\n",
    "        print(f\"Step 1: Initial retrieval (top-{initial_top_k})...\")\n",
    "        initial_results, original_query_embedding = basic_search(query, initial_top_k)\n",
    "        \n",
    "        # Step 2: Compute dimension importance using magnitude\n",
    "        print(f\"Step 2: Computing dimension importance using magnitude...\")\n",
    "        importance_scores = np.abs(original_query_embedding)\n",
    "        \n",
    "        # Step 3: Zero out least important dimensions based on magnitude\n",
    "        print(f\"Step 3: Zeroing out {zero_out_ratio*100}% least important dimensions...\")\n",
    "        alpha = 1 - zero_out_ratio\n",
    "        modified_query_embedding = self._zero_out_by_magnitude(original_query_embedding, importance_scores, alpha)\n",
    "        \n",
    "        # Step 4: Re-score all initial results with modified query\n",
    "        print(f\"Step 4: Re-scoring with modified query...\")\n",
    "        reranked_results = []\n",
    "        for result in initial_results:\n",
    "            new_score = float(np.dot(modified_query_embedding, result['embedding']))\n",
    "            reranked_results.append({\n",
    "                'rank': result['rank'],\n",
    "                'index': result['index'],\n",
    "                'product_id': result['product_id'],\n",
    "                'title': result['title'],\n",
    "                'original_score': result['score'],\n",
    "                'new_score': new_score\n",
    "            })\n",
    "        \n",
    "        # Sort by new scores and take top-k\n",
    "        reranked_results.sort(key=lambda x: -x['new_score'])\n",
    "        final_results = reranked_results[:final_top_k]\n",
    "        \n",
    "        # Update ranks\n",
    "        for i, result in enumerate(final_results):\n",
    "            result['rank'] = i + 1\n",
    "        \n",
    "        return {\n",
    "            'method': 'magnitude_rerank',\n",
    "            'query': query,\n",
    "            'zero_out_ratio': zero_out_ratio,\n",
    "            'original_results': initial_results[:final_top_k],\n",
    "            'reranked_results': final_results,\n",
    "            'importance_scores': importance_scores,\n",
    "            'original_query_embedding': original_query_embedding,\n",
    "            'modified_query_embedding': modified_query_embedding\n",
    "        }\n",
    "    \n",
    "    def magnitude_refetch(self, query, final_top_k=10, zero_out_ratio=0.2):\n",
    "        \"\"\"\n",
    "        Magnitude-based refetching: use query magnitude to determine importance and perform new retrieval\n",
    "        \n",
    "        Args:\n",
    "            query: Search query text\n",
    "            final_top_k: Number of final results to return after refetch\n",
    "            zero_out_ratio: Fraction of dimensions to zero out\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with original and refetched results\n",
    "        \"\"\"\n",
    "        # Step 1: Get original query embedding and initial results for comparison\n",
    "        print(f\"Step 1: Getting original query embedding...\")\n",
    "        original_results, original_query_embedding = basic_search(query, final_top_k)\n",
    "        \n",
    "        # Step 2: Compute dimension importance using magnitude\n",
    "        print(f\"Step 2: Computing dimension importance using magnitude...\")\n",
    "        importance_scores = np.abs(original_query_embedding)\n",
    "        \n",
    "        # Step 3: Zero out least important dimensions based on magnitude\n",
    "        print(f\"Step 3: Zeroing out {zero_out_ratio*100}% least important dimensions...\")\n",
    "        alpha = 1 - zero_out_ratio\n",
    "        modified_query_embedding = self._zero_out_by_magnitude(original_query_embedding, importance_scores, alpha)\n",
    "        \n",
    "        # Step 4: Perform new retrieval with modified query\n",
    "        print(f\"Step 4: Performing new retrieval with modified query...\")\n",
    "        refetch_scores = np.dot(self.embeddings, modified_query_embedding)\n",
    "        top_indices = np.argsort(refetch_scores)[::-1][:final_top_k]\n",
    "        \n",
    "        refetched_results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            refetched_results.append({\n",
    "                'rank': i + 1,\n",
    "                'index': idx,\n",
    "                'product_id': self.df.iloc[idx]['product_id'],\n",
    "                'title': self.df.iloc[idx]['title'],\n",
    "                'score': refetch_scores[idx]\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'method': 'magnitude_refetch',\n",
    "            'query': query,\n",
    "            'zero_out_ratio': zero_out_ratio,\n",
    "            'original_results': original_results,\n",
    "            'refetched_results': refetched_results,\n",
    "            'importance_scores': importance_scores,\n",
    "            'original_query_embedding': original_query_embedding,\n",
    "            'modified_query_embedding': modified_query_embedding\n",
    "        }\n",
    "    \n",
    "    def _zero_out_by_magnitude(self, query_vector, importance_scores, alpha=0.8):\n",
    "        \"\"\"\n",
    "        Zero out the lowest (1-alpha) fraction of dimensions based on magnitude importance\n",
    "        \n",
    "        Args:\n",
    "            query_vector: Original query vector\n",
    "            importance_scores: Magnitude-based importance scores (|qi|)\n",
    "            alpha: Fraction of dimensions to keep (0.8 means keep 80%)\n",
    "            \n",
    "        Returns:\n",
    "            Modified query vector with least important dimensions zeroed out\n",
    "        \"\"\"\n",
    "        dim = len(importance_scores)\n",
    "        keep_count = int(alpha * dim)\n",
    "        \n",
    "        if keep_count >= dim:\n",
    "            return query_vector.copy()\n",
    "        \n",
    "        # Get indices of most important dimensions (highest magnitude)\n",
    "        sorted_indices = np.argsort(importance_scores)\n",
    "        keep_indices = set(sorted_indices[-keep_count:])\n",
    "        \n",
    "        # Zero out least important dimensions\n",
    "        modified_query_vector = query_vector.copy()\n",
    "        for i in range(dim):\n",
    "            if i not in keep_indices:\n",
    "                modified_query_vector[i] = 0.0\n",
    "        \n",
    "        return modified_query_vector\n",
    "\n",
    "# Initialize Magnitude-based DIME\n",
    "magnitude_dime = MagnitudeBasedDIME(model, product_embeddings, df)\n",
    "print(\"Magnitude-based DIME initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47307df",
   "metadata": {},
   "source": [
    "## 3. Testing and Comparison\n",
    "\n",
    "Let's test all six approaches (PRF rerank, PRF refetch, LLM rerank, LLM refetch, Magnitude rerank, Magnitude refetch) with sample queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62f54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing Query: 'black dress shirt'\n",
      "============================================================\n",
      "\n",
      "1. PRF RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: elegant black dress shirt formal business professional men's clothing cotton long sleeve button up office wear\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: elegant black dress shirt formal business professional men's clothing cotton long sleeve button up office wear\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: elegant black dress shirt formal business professional men's clothing cotton long sleeve button up office wear\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: elegant black dress shirt formal business professional men's clothing cotton long sleeve button up office wear\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'black dress shirt'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. J.Crew Black Blouses - Score: 0.5945\n",
      "2. Gap Black Blouses - Score: 0.5807\n",
      "3. Hollister Black T-Shirts in Viscose - Score: 0.5762\n",
      "4. American Eagle Black T-Shirts - Score: 0.5690\n",
      "5. Burberry Black Casual Shirts in Viscose - Score: 0.5592\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. Hollister Black T-Shirts in Viscose - Score: 0.6342\n",
      "2. J.Crew Black Blouses - Score: 0.6258\n",
      "3. American Eagle Black T-Shirts - Score: 0.6210\n",
      "4. Gap Black Blouses - Score: 0.6147\n",
      "5. Burberry Black Casual Shirts in Viscose - Score: 0.6086\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Hollister Black T-Shirts in Viscose - Score: 0.6342\n",
      "2. J.Crew Black Blouses - Score: 0.6258\n",
      "3. American Eagle Black T-Shirts - Score: 0.6210\n",
      "4. Gap Black Blouses - Score: 0.6147\n",
      "5. Burberry Black Casual Shirts in Viscose - Score: 0.6086\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. J.Crew Black Blouses - Score: 0.5340\n",
      "2. Burberry Black Casual Shirts in Viscose - Score: 0.5320\n",
      "3. American Eagle Black T-Shirts - Score: 0.5257\n",
      "4. Hollister Black Swimwear - Score: 0.5202\n",
      "5. Hollister Black T-Shirts in Viscose - Score: 0.5187\n",
      "   LLM Doc: elegant black dress shirt formal business professional men's clothing cotton long sleeve button up o...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. J.Crew Black Blouses - Score: 0.5340\n",
      "2. Burberry Black Casual Shirts in Viscose - Score: 0.5320\n",
      "3. American Eagle Black T-Shirts - Score: 0.5257\n",
      "4. Hollister Black Swimwear - Score: 0.5202\n",
      "5. Hollister Black T-Shirts in Viscose - Score: 0.5187\n",
      "   LLM Doc: elegant black dress shirt formal business professional men's clothing cotton long sleeve button up o...\n",
      "\n",
      "============================================================\n",
      "Testing Query: 'blue jeans'\n",
      "============================================================\n",
      "\n",
      "1. PRF RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'black dress shirt'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. J.Crew Black Blouses - Score: 0.5945\n",
      "2. Gap Black Blouses - Score: 0.5807\n",
      "3. Hollister Black T-Shirts in Viscose - Score: 0.5762\n",
      "4. American Eagle Black T-Shirts - Score: 0.5690\n",
      "5. Burberry Black Casual Shirts in Viscose - Score: 0.5592\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. Hollister Black T-Shirts in Viscose - Score: 0.6342\n",
      "2. J.Crew Black Blouses - Score: 0.6258\n",
      "3. American Eagle Black T-Shirts - Score: 0.6210\n",
      "4. Gap Black Blouses - Score: 0.6147\n",
      "5. Burberry Black Casual Shirts in Viscose - Score: 0.6086\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Hollister Black T-Shirts in Viscose - Score: 0.6342\n",
      "2. J.Crew Black Blouses - Score: 0.6258\n",
      "3. American Eagle Black T-Shirts - Score: 0.6210\n",
      "4. Gap Black Blouses - Score: 0.6147\n",
      "5. Burberry Black Casual Shirts in Viscose - Score: 0.6086\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. J.Crew Black Blouses - Score: 0.5340\n",
      "2. Burberry Black Casual Shirts in Viscose - Score: 0.5320\n",
      "3. American Eagle Black T-Shirts - Score: 0.5257\n",
      "4. Hollister Black Swimwear - Score: 0.5202\n",
      "5. Hollister Black T-Shirts in Viscose - Score: 0.5187\n",
      "   LLM Doc: elegant black dress shirt formal business professional men's clothing cotton long sleeve button up o...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. J.Crew Black Blouses - Score: 0.5340\n",
      "2. Burberry Black Casual Shirts in Viscose - Score: 0.5320\n",
      "3. American Eagle Black T-Shirts - Score: 0.5257\n",
      "4. Hollister Black Swimwear - Score: 0.5202\n",
      "5. Hollister Black T-Shirts in Viscose - Score: 0.5187\n",
      "   LLM Doc: elegant black dress shirt formal business professional men's clothing cotton long sleeve button up o...\n",
      "\n",
      "============================================================\n",
      "Testing Query: 'blue jeans'\n",
      "============================================================\n",
      "\n",
      "1. PRF RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: blue denim jeans casual wear pants trousers men women comfortable cotton everyday fashion\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: blue denim jeans casual wear pants trousers men women comfortable cotton everyday fashion\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: blue denim jeans casual wear pants trousers men women comfortable cotton everyday fashion\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: blue denim jeans casual wear pants trousers men women comfortable cotton everyday fashion\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'blue jeans'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. Gap Blue Jeans in Suede - Score: 0.6695\n",
      "2. Hollister Blue Jeans in Acrylic - Score: 0.6394\n",
      "3. COS Blue Jeans in Wool - Score: 0.6391\n",
      "4. J.Crew Blue Skirts in Denim - Score: 0.6225\n",
      "5. COS Purple Jeans - Score: 0.6168\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. Gap Blue Jeans in Suede - Score: 0.6944\n",
      "2. Hollister Blue Jeans in Acrylic - Score: 0.6722\n",
      "3. COS Blue Jeans in Wool - Score: 0.6682\n",
      "4. COS Purple Jeans - Score: 0.6493\n",
      "5. J.Crew Blue Skirts in Denim - Score: 0.6442\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Gap Blue Jeans in Suede - Score: 0.6944\n",
      "2. Hollister Blue Jeans in Acrylic - Score: 0.6722\n",
      "3. COS Blue Jeans in Wool - Score: 0.6682\n",
      "4. COS Purple Jeans - Score: 0.6493\n",
      "5. J.Crew Blue Skirts in Denim - Score: 0.6442\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. Gap Blue Jeans in Suede - Score: 0.6467\n",
      "2. Hollister Blue Jeans in Acrylic - Score: 0.6269\n",
      "3. COS Blue Jeans in Wool - Score: 0.6268\n",
      "4. COS Purple Jeans - Score: 0.6088\n",
      "5. J.Crew Blue Skirts in Denim - Score: 0.6012\n",
      "   LLM Doc: blue denim jeans casual wear pants trousers men women comfortable cotton everyday fashion...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Gap Blue Jeans in Suede - Score: 0.6467\n",
      "2. Hollister Blue Jeans in Acrylic - Score: 0.6269\n",
      "3. COS Blue Jeans in Wool - Score: 0.6268\n",
      "4. COS Purple Jeans - Score: 0.6088\n",
      "5. J.Crew Blue Skirts in Denim - Score: 0.6012\n",
      "   LLM Doc: blue denim jeans casual wear pants trousers men women comfortable cotton everyday fashion...\n",
      "\n",
      "============================================================\n",
      "Testing Query: 'white sneakers'\n",
      "============================================================\n",
      "\n",
      "1. PRF RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'blue jeans'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. Gap Blue Jeans in Suede - Score: 0.6695\n",
      "2. Hollister Blue Jeans in Acrylic - Score: 0.6394\n",
      "3. COS Blue Jeans in Wool - Score: 0.6391\n",
      "4. J.Crew Blue Skirts in Denim - Score: 0.6225\n",
      "5. COS Purple Jeans - Score: 0.6168\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. Gap Blue Jeans in Suede - Score: 0.6944\n",
      "2. Hollister Blue Jeans in Acrylic - Score: 0.6722\n",
      "3. COS Blue Jeans in Wool - Score: 0.6682\n",
      "4. COS Purple Jeans - Score: 0.6493\n",
      "5. J.Crew Blue Skirts in Denim - Score: 0.6442\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Gap Blue Jeans in Suede - Score: 0.6944\n",
      "2. Hollister Blue Jeans in Acrylic - Score: 0.6722\n",
      "3. COS Blue Jeans in Wool - Score: 0.6682\n",
      "4. COS Purple Jeans - Score: 0.6493\n",
      "5. J.Crew Blue Skirts in Denim - Score: 0.6442\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. Gap Blue Jeans in Suede - Score: 0.6467\n",
      "2. Hollister Blue Jeans in Acrylic - Score: 0.6269\n",
      "3. COS Blue Jeans in Wool - Score: 0.6268\n",
      "4. COS Purple Jeans - Score: 0.6088\n",
      "5. J.Crew Blue Skirts in Denim - Score: 0.6012\n",
      "   LLM Doc: blue denim jeans casual wear pants trousers men women comfortable cotton everyday fashion...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Gap Blue Jeans in Suede - Score: 0.6467\n",
      "2. Hollister Blue Jeans in Acrylic - Score: 0.6269\n",
      "3. COS Blue Jeans in Wool - Score: 0.6268\n",
      "4. COS Purple Jeans - Score: 0.6088\n",
      "5. J.Crew Blue Skirts in Denim - Score: 0.6012\n",
      "   LLM Doc: blue denim jeans casual wear pants trousers men women comfortable cotton everyday fashion...\n",
      "\n",
      "============================================================\n",
      "Testing Query: 'white sneakers'\n",
      "============================================================\n",
      "\n",
      "1. PRF RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: white athletic sneakers shoes casual sports footwear comfortable rubber sole walking running\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: white athletic sneakers shoes casual sports footwear comfortable rubber sole walking running\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'white sneakers'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. Gap White Sneakers - Score: 0.7189\n",
      "2. Uniqlo White Sneakers in Leather - Score: 0.7051\n",
      "3. COS Gray Sneakers - Score: 0.6921\n",
      "4. Uniqlo White Sneakers in Polyester - Score: 0.6899\n",
      "5. COS Gray Sneakers - Score: 0.6701\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. Uniqlo White Sneakers in Leather - Score: 0.7302\n",
      "2. Gap White Sneakers - Score: 0.7205\n",
      "3. COS Gray Sneakers - Score: 0.7175\n",
      "4. Uniqlo White Sneakers in Polyester - Score: 0.7108\n",
      "5. COS Gray Sneakers - Score: 0.6976\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Uniqlo White Sneakers in Leather - Score: 0.7302\n",
      "2. Gap White Sneakers - Score: 0.7205\n",
      "3. COS Gray Sneakers - Score: 0.7175\n",
      "4. Uniqlo White Sneakers in Polyester - Score: 0.7108\n",
      "5. COS Gray Sneakers - Score: 0.6976\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. Gap White Sneakers - Score: 0.6832\n",
      "2. Uniqlo White Sneakers in Leather - Score: 0.6709\n",
      "3. Uniqlo White Sneakers in Polyester - Score: 0.6493\n",
      "4. COS Gray Sneakers - Score: 0.6359\n",
      "5. Old Navy Yellow Sneakers - Score: 0.6181\n",
      "   LLM Doc: white athletic sneakers shoes casual sports footwear comfortable rubber sole walking running...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Gap White Sneakers - Score: 0.6832\n",
      "2. Uniqlo White Sneakers in Leather - Score: 0.6709\n",
      "3. Uniqlo White Sneakers in Polyester - Score: 0.6493\n",
      "4. COS Gray Sneakers - Score: 0.6359\n",
      "5. Old Navy Yellow Sneakers - Score: 0.6181\n",
      "   LLM Doc: white athletic sneakers shoes casual sports footwear comfortable rubber sole walking running...\n",
      "\n",
      "============================================================\n",
      "Testing Query: 'red dress'\n",
      "============================================================\n",
      "\n",
      "1. PRF RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: white athletic sneakers shoes casual sports footwear comfortable rubber sole walking running\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: white athletic sneakers shoes casual sports footwear comfortable rubber sole walking running\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'white sneakers'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. Gap White Sneakers - Score: 0.7189\n",
      "2. Uniqlo White Sneakers in Leather - Score: 0.7051\n",
      "3. COS Gray Sneakers - Score: 0.6921\n",
      "4. Uniqlo White Sneakers in Polyester - Score: 0.6899\n",
      "5. COS Gray Sneakers - Score: 0.6701\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. Uniqlo White Sneakers in Leather - Score: 0.7302\n",
      "2. Gap White Sneakers - Score: 0.7205\n",
      "3. COS Gray Sneakers - Score: 0.7175\n",
      "4. Uniqlo White Sneakers in Polyester - Score: 0.7108\n",
      "5. COS Gray Sneakers - Score: 0.6976\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Uniqlo White Sneakers in Leather - Score: 0.7302\n",
      "2. Gap White Sneakers - Score: 0.7205\n",
      "3. COS Gray Sneakers - Score: 0.7175\n",
      "4. Uniqlo White Sneakers in Polyester - Score: 0.7108\n",
      "5. COS Gray Sneakers - Score: 0.6976\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. Gap White Sneakers - Score: 0.6832\n",
      "2. Uniqlo White Sneakers in Leather - Score: 0.6709\n",
      "3. Uniqlo White Sneakers in Polyester - Score: 0.6493\n",
      "4. COS Gray Sneakers - Score: 0.6359\n",
      "5. Old Navy Yellow Sneakers - Score: 0.6181\n",
      "   LLM Doc: white athletic sneakers shoes casual sports footwear comfortable rubber sole walking running...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Gap White Sneakers - Score: 0.6832\n",
      "2. Uniqlo White Sneakers in Leather - Score: 0.6709\n",
      "3. Uniqlo White Sneakers in Polyester - Score: 0.6493\n",
      "4. COS Gray Sneakers - Score: 0.6359\n",
      "5. Old Navy Yellow Sneakers - Score: 0.6181\n",
      "   LLM Doc: white athletic sneakers shoes casual sports footwear comfortable rubber sole walking running...\n",
      "\n",
      "============================================================\n",
      "Testing Query: 'red dress'\n",
      "============================================================\n",
      "\n",
      "1. PRF RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: red dress women's formal elegant party evening wear special occasion outfit stylish\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: red dress women's formal elegant party evening wear special occasion outfit stylish\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'red dress'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. Hollister Red Formal Dresses in Denim - Score: 0.6673\n",
      "2. H&M Red Mini Dresses - Score: 0.6530\n",
      "3. PrettyLittleThing Red Dress Pants - Score: 0.6506\n",
      "4. H&M Red Mini Dresses - Score: 0.6383\n",
      "5. Hollister Red Dress Pants - Score: 0.6251\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. Hollister Red Formal Dresses in Denim - Score: 0.7041\n",
      "2. PrettyLittleThing Red Dress Pants - Score: 0.6917\n",
      "3. H&M Red Mini Dresses - Score: 0.6819\n",
      "4. H&M Red Mini Dresses - Score: 0.6701\n",
      "5. Hollister Red Dress Pants - Score: 0.6684\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Hollister Red Formal Dresses in Denim - Score: 0.7041\n",
      "2. PrettyLittleThing Red Dress Pants - Score: 0.6917\n",
      "3. H&M Red Mini Dresses - Score: 0.6819\n",
      "4. H&M Red Mini Dresses - Score: 0.6701\n",
      "5. Hollister Red Dress Pants - Score: 0.6684\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. Hollister Red Formal Dresses in Denim - Score: 0.6425\n",
      "2. PrettyLittleThing Red Dress Pants - Score: 0.6274\n",
      "3. H&M Red Mini Dresses - Score: 0.6137\n",
      "4. H&M Red Mini Dresses - Score: 0.6000\n",
      "5. Hollister Red Dress Pants - Score: 0.5975\n",
      "   LLM Doc: red dress women's formal elegant party evening wear special occasion outfit stylish...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Hollister Red Formal Dresses in Denim - Score: 0.6425\n",
      "2. PrettyLittleThing Red Dress Pants - Score: 0.6274\n",
      "3. H&M Red Mini Dresses - Score: 0.6137\n",
      "4. H&M Red Mini Dresses - Score: 0.6000\n",
      "5. Hollister Red Dress Pants - Score: 0.5975\n",
      "   LLM Doc: red dress women's formal elegant party evening wear special occasion outfit stylish...\n",
      "\n",
      "============================================================\n",
      "Testing Query: 'casual t-shirt'\n",
      "============================================================\n",
      "\n",
      "1. PRF RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: red dress women's formal elegant party evening wear special occasion outfit stylish\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: red dress women's formal elegant party evening wear special occasion outfit stylish\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'red dress'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. Hollister Red Formal Dresses in Denim - Score: 0.6673\n",
      "2. H&M Red Mini Dresses - Score: 0.6530\n",
      "3. PrettyLittleThing Red Dress Pants - Score: 0.6506\n",
      "4. H&M Red Mini Dresses - Score: 0.6383\n",
      "5. Hollister Red Dress Pants - Score: 0.6251\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. Hollister Red Formal Dresses in Denim - Score: 0.7041\n",
      "2. PrettyLittleThing Red Dress Pants - Score: 0.6917\n",
      "3. H&M Red Mini Dresses - Score: 0.6819\n",
      "4. H&M Red Mini Dresses - Score: 0.6701\n",
      "5. Hollister Red Dress Pants - Score: 0.6684\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Hollister Red Formal Dresses in Denim - Score: 0.7041\n",
      "2. PrettyLittleThing Red Dress Pants - Score: 0.6917\n",
      "3. H&M Red Mini Dresses - Score: 0.6819\n",
      "4. H&M Red Mini Dresses - Score: 0.6701\n",
      "5. Hollister Red Dress Pants - Score: 0.6684\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. Hollister Red Formal Dresses in Denim - Score: 0.6425\n",
      "2. PrettyLittleThing Red Dress Pants - Score: 0.6274\n",
      "3. H&M Red Mini Dresses - Score: 0.6137\n",
      "4. H&M Red Mini Dresses - Score: 0.6000\n",
      "5. Hollister Red Dress Pants - Score: 0.5975\n",
      "   LLM Doc: red dress women's formal elegant party evening wear special occasion outfit stylish...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Hollister Red Formal Dresses in Denim - Score: 0.6425\n",
      "2. PrettyLittleThing Red Dress Pants - Score: 0.6274\n",
      "3. H&M Red Mini Dresses - Score: 0.6137\n",
      "4. H&M Red Mini Dresses - Score: 0.6000\n",
      "5. Hollister Red Dress Pants - Score: 0.5975\n",
      "   LLM Doc: red dress women's formal elegant party evening wear special occasion outfit stylish...\n",
      "\n",
      "============================================================\n",
      "Testing Query: 'casual t-shirt'\n",
      "============================================================\n",
      "\n",
      "1. PRF RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: casual t-shirt comfortable cotton everyday wear men women basic wardrobe essential\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: casual t-shirt comfortable cotton everyday wear men women basic wardrobe essential\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: casual t-shirt comfortable cotton everyday wear men women basic wardrobe essential\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: casual t-shirt comfortable cotton everyday wear men women basic wardrobe essential\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'casual t-shirt'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. Old Navy Cream Casual Shirts - Score: 0.6248\n",
      "2. Old Navy Cream T-Shirts - Score: 0.6002\n",
      "3. Old Navy Gray Casual Shirts in Acrylic - Score: 0.5969\n",
      "4. COS Brown Casual Shirts in Viscose - Score: 0.5862\n",
      "5. Gucci Coral Casual Shirts - Score: 0.5825\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. Old Navy Cream Casual Shirts - Score: 0.6637\n",
      "2. Old Navy Gray Casual Shirts in Acrylic - Score: 0.6370\n",
      "3. Old Navy Cream T-Shirts - Score: 0.6305\n",
      "4. Gucci Coral Casual Shirts - Score: 0.6120\n",
      "5. COS Brown Casual Shirts in Viscose - Score: 0.6052\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Old Navy Cream Casual Shirts - Score: 0.6637\n",
      "2. Old Navy Gray Casual Shirts in Acrylic - Score: 0.6370\n",
      "3. Old Navy Cream T-Shirts - Score: 0.6305\n",
      "4. Gucci Coral Casual Shirts - Score: 0.6120\n",
      "5. COS Brown Casual Shirts in Viscose - Score: 0.6052\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. Old Navy Cream Casual Shirts - Score: 0.6012\n",
      "2. Old Navy Cream T-Shirts - Score: 0.5758\n",
      "3. Old Navy Gray Casual Shirts in Acrylic - Score: 0.5723\n",
      "4. Old Navy Blue T-Shirts in Nylon - Score: 0.5642\n",
      "5. COS Brown Casual Shirts in Viscose - Score: 0.5583\n",
      "   LLM Doc: casual t-shirt comfortable cotton everyday wear men women basic wardrobe essential...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Old Navy Cream Casual Shirts - Score: 0.6012\n",
      "2. Old Navy Cream T-Shirts - Score: 0.5758\n",
      "3. Old Navy Gray Casual Shirts in Acrylic - Score: 0.5723\n",
      "4. Old Navy Blue T-Shirts in Nylon - Score: 0.5642\n",
      "5. COS Brown Casual Shirts in Viscose - Score: 0.5583\n",
      "   LLM Doc: casual t-shirt comfortable cotton everyday wear men women basic wardrobe essential...\n",
      "\n",
      "============================================================\n",
      "Testing Query: 'winter coat'\n",
      "============================================================\n",
      "\n",
      "1. PRF RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'casual t-shirt'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. Old Navy Cream Casual Shirts - Score: 0.6248\n",
      "2. Old Navy Cream T-Shirts - Score: 0.6002\n",
      "3. Old Navy Gray Casual Shirts in Acrylic - Score: 0.5969\n",
      "4. COS Brown Casual Shirts in Viscose - Score: 0.5862\n",
      "5. Gucci Coral Casual Shirts - Score: 0.5825\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. Old Navy Cream Casual Shirts - Score: 0.6637\n",
      "2. Old Navy Gray Casual Shirts in Acrylic - Score: 0.6370\n",
      "3. Old Navy Cream T-Shirts - Score: 0.6305\n",
      "4. Gucci Coral Casual Shirts - Score: 0.6120\n",
      "5. COS Brown Casual Shirts in Viscose - Score: 0.6052\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Old Navy Cream Casual Shirts - Score: 0.6637\n",
      "2. Old Navy Gray Casual Shirts in Acrylic - Score: 0.6370\n",
      "3. Old Navy Cream T-Shirts - Score: 0.6305\n",
      "4. Gucci Coral Casual Shirts - Score: 0.6120\n",
      "5. COS Brown Casual Shirts in Viscose - Score: 0.6052\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. Old Navy Cream Casual Shirts - Score: 0.6012\n",
      "2. Old Navy Cream T-Shirts - Score: 0.5758\n",
      "3. Old Navy Gray Casual Shirts in Acrylic - Score: 0.5723\n",
      "4. Old Navy Blue T-Shirts in Nylon - Score: 0.5642\n",
      "5. COS Brown Casual Shirts in Viscose - Score: 0.5583\n",
      "   LLM Doc: casual t-shirt comfortable cotton everyday wear men women basic wardrobe essential...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. Old Navy Cream Casual Shirts - Score: 0.6012\n",
      "2. Old Navy Cream T-Shirts - Score: 0.5758\n",
      "3. Old Navy Gray Casual Shirts in Acrylic - Score: 0.5723\n",
      "4. Old Navy Blue T-Shirts in Nylon - Score: 0.5642\n",
      "5. COS Brown Casual Shirts in Viscose - Score: 0.5583\n",
      "   LLM Doc: casual t-shirt comfortable cotton everyday wear men women basic wardrobe essential...\n",
      "\n",
      "============================================================\n",
      "Testing Query: 'winter coat'\n",
      "============================================================\n",
      "\n",
      "1. PRF RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: winter coat warm jacket outerwear cold weather protection insulated heavy duty\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: winter coat warm jacket outerwear cold weather protection insulated heavy duty\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: winter coat warm jacket outerwear cold weather protection insulated heavy duty\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: winter coat warm jacket outerwear cold weather protection insulated heavy duty\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'winter coat'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. COS Black Coats - Score: 0.4631\n",
      "2. COS Yellow Jackets - Score: 0.3912\n",
      "3. Hollister Pink Jackets - Score: 0.3869\n",
      "4. Primark Red Coats - Score: 0.3848\n",
      "5. Old Navy Gray Coats - Score: 0.3797\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. COS Black Coats - Score: 0.5314\n",
      "2. COS Yellow Jackets - Score: 0.4735\n",
      "3. Hollister Pink Jackets - Score: 0.4657\n",
      "4. Primark Red Coats - Score: 0.4533\n",
      "5. COS Brown Jackets - Score: 0.4326\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. COS Black Coats - Score: 0.5314\n",
      "2. COS Yellow Jackets - Score: 0.4735\n",
      "3. Hollister Pink Jackets - Score: 0.4657\n",
      "4. Primark Red Coats - Score: 0.4533\n",
      "5. COS Brown Jackets - Score: 0.4326\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. COS Black Coats - Score: 0.4357\n",
      "2. COS Yellow Jackets - Score: 0.3891\n",
      "3. American Eagle Orange Jackets in Wool - Score: 0.3663\n",
      "4. Hollister Pink Jackets - Score: 0.3652\n",
      "5. J.Crew Red Jackets - Score: 0.3625\n",
      "   LLM Doc: winter coat warm jacket outerwear cold weather protection insulated heavy duty...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. COS Black Coats - Score: 0.4357\n",
      "2. COS Yellow Jackets - Score: 0.3891\n",
      "3. American Eagle Orange Jackets in Wool - Score: 0.3663\n",
      "4. Hollister Pink Jackets - Score: 0.3652\n",
      "5. J.Crew Red Jackets - Score: 0.3625\n",
      "   LLM Doc: winter coat warm jacket outerwear cold weather protection insulated heavy duty...\n",
      "\n",
      "============================================================\n",
      "Testing Query: 'summer dress'\n",
      "============================================================\n",
      "\n",
      "1. PRF RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'winter coat'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. COS Black Coats - Score: 0.4631\n",
      "2. COS Yellow Jackets - Score: 0.3912\n",
      "3. Hollister Pink Jackets - Score: 0.3869\n",
      "4. Primark Red Coats - Score: 0.3848\n",
      "5. Old Navy Gray Coats - Score: 0.3797\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. COS Black Coats - Score: 0.5314\n",
      "2. COS Yellow Jackets - Score: 0.4735\n",
      "3. Hollister Pink Jackets - Score: 0.4657\n",
      "4. Primark Red Coats - Score: 0.4533\n",
      "5. COS Brown Jackets - Score: 0.4326\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. COS Black Coats - Score: 0.5314\n",
      "2. COS Yellow Jackets - Score: 0.4735\n",
      "3. Hollister Pink Jackets - Score: 0.4657\n",
      "4. Primark Red Coats - Score: 0.4533\n",
      "5. COS Brown Jackets - Score: 0.4326\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. COS Black Coats - Score: 0.4357\n",
      "2. COS Yellow Jackets - Score: 0.3891\n",
      "3. American Eagle Orange Jackets in Wool - Score: 0.3663\n",
      "4. Hollister Pink Jackets - Score: 0.3652\n",
      "5. J.Crew Red Jackets - Score: 0.3625\n",
      "   LLM Doc: winter coat warm jacket outerwear cold weather protection insulated heavy duty...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. COS Black Coats - Score: 0.4357\n",
      "2. COS Yellow Jackets - Score: 0.3891\n",
      "3. American Eagle Orange Jackets in Wool - Score: 0.3663\n",
      "4. Hollister Pink Jackets - Score: 0.3652\n",
      "5. J.Crew Red Jackets - Score: 0.3625\n",
      "   LLM Doc: winter coat warm jacket outerwear cold weather protection insulated heavy duty...\n",
      "\n",
      "============================================================\n",
      "Testing Query: 'summer dress'\n",
      "============================================================\n",
      "\n",
      "1. PRF RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "2. PRF REFETCH:\n",
      "Step 1: Initial retrieval for PRF (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Computing centroid from top-5 PRF documents...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "3. LLM RERANK:\n",
      "Step 1: Initial retrieval (top-1000)...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: summer dress light breathable women's warm weather casual comfortable seasonal clothing\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: summer dress light breathable women's warm weather casual comfortable seasonal clothing\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: summer dress light breathable women's warm weather casual comfortable seasonal clothing\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Re-scoring with modified query...\n",
      "\n",
      "4. LLM REFETCH:\n",
      "Step 1: Getting original query embedding...\n",
      "Step 2: Generating and embedding LLM document...\n",
      "Generated LLM doc: summer dress light breathable women's warm weather casual comfortable seasonal clothing\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'summer dress'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. H&M Yellow Mini Dresses - Score: 0.5662\n",
      "2. PrettyLittleThing Yellow Mini Dresses - Score: 0.5450\n",
      "3. H&M Blue Mini Dresses - Score: 0.5306\n",
      "4. COS Orange Casual Dresses - Score: 0.5261\n",
      "5. H&M Purple Dresses - Score: 0.5169\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. H&M Yellow Mini Dresses - Score: 0.6395\n",
      "2. PrettyLittleThing Yellow Mini Dresses - Score: 0.5983\n",
      "3. H&M Blue Mini Dresses - Score: 0.5931\n",
      "4. H&M Purple Dresses - Score: 0.5815\n",
      "5. H&M Red Mini Dresses - Score: 0.5705\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. H&M Yellow Mini Dresses - Score: 0.6395\n",
      "2. PrettyLittleThing Yellow Mini Dresses - Score: 0.5983\n",
      "3. H&M Blue Mini Dresses - Score: 0.5931\n",
      "4. H&M Purple Dresses - Score: 0.5815\n",
      "5. H&M Red Mini Dresses - Score: 0.5705\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. H&M Yellow Mini Dresses - Score: 0.5366\n",
      "2. PrettyLittleThing Yellow Mini Dresses - Score: 0.5157\n",
      "3. H&M Blue Mini Dresses - Score: 0.5082\n",
      "4. H&M Purple Dresses - Score: 0.5053\n",
      "5. H&M Green Casual Dresses - Score: 0.5046\n",
      "   LLM Doc: summer dress light breathable women's warm weather casual comfortable seasonal clothing...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. H&M Yellow Mini Dresses - Score: 0.5366\n",
      "2. PrettyLittleThing Yellow Mini Dresses - Score: 0.5157\n",
      "3. H&M Blue Mini Dresses - Score: 0.5082\n",
      "4. H&M Purple Dresses - Score: 0.5053\n",
      "5. H&M Green Casual Dresses - Score: 0.5046\n",
      "   LLM Doc: summer dress light breathable women's warm weather casual comfortable seasonal clothing...\n",
      "Step 3: Zeroing out 20.0% least important dimensions...\n",
      "Step 4: Performing new retrieval with modified query...\n",
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON FOR: 'summer dress'\n",
      "================================================================================\n",
      "\n",
      "BASELINE (Original Dense Retrieval):\n",
      "--------------------------------------------------\n",
      "1. H&M Yellow Mini Dresses - Score: 0.5662\n",
      "2. PrettyLittleThing Yellow Mini Dresses - Score: 0.5450\n",
      "3. H&M Blue Mini Dresses - Score: 0.5306\n",
      "4. COS Orange Casual Dresses - Score: 0.5261\n",
      "5. H&M Purple Dresses - Score: 0.5169\n",
      "\n",
      "PRF RERANK:\n",
      "--------------------------------------------------\n",
      "1. H&M Yellow Mini Dresses - Score: 0.6395\n",
      "2. PrettyLittleThing Yellow Mini Dresses - Score: 0.5983\n",
      "3. H&M Blue Mini Dresses - Score: 0.5931\n",
      "4. H&M Purple Dresses - Score: 0.5815\n",
      "5. H&M Red Mini Dresses - Score: 0.5705\n",
      "\n",
      "PRF REFETCH:\n",
      "--------------------------------------------------\n",
      "1. H&M Yellow Mini Dresses - Score: 0.6395\n",
      "2. PrettyLittleThing Yellow Mini Dresses - Score: 0.5983\n",
      "3. H&M Blue Mini Dresses - Score: 0.5931\n",
      "4. H&M Purple Dresses - Score: 0.5815\n",
      "5. H&M Red Mini Dresses - Score: 0.5705\n",
      "\n",
      "LLM RERANK:\n",
      "--------------------------------------------------\n",
      "1. H&M Yellow Mini Dresses - Score: 0.5366\n",
      "2. PrettyLittleThing Yellow Mini Dresses - Score: 0.5157\n",
      "3. H&M Blue Mini Dresses - Score: 0.5082\n",
      "4. H&M Purple Dresses - Score: 0.5053\n",
      "5. H&M Green Casual Dresses - Score: 0.5046\n",
      "   LLM Doc: summer dress light breathable women's warm weather casual comfortable seasonal clothing...\n",
      "\n",
      "LLM REFETCH:\n",
      "--------------------------------------------------\n",
      "1. H&M Yellow Mini Dresses - Score: 0.5366\n",
      "2. PrettyLittleThing Yellow Mini Dresses - Score: 0.5157\n",
      "3. H&M Blue Mini Dresses - Score: 0.5082\n",
      "4. H&M Purple Dresses - Score: 0.5053\n",
      "5. H&M Green Casual Dresses - Score: 0.5046\n",
      "   LLM Doc: summer dress light breathable women's warm weather casual comfortable seasonal clothing...\n"
     ]
    }
   ],
   "source": [
    "def test_all_approaches(query, prf_k=5, zero_out_ratio=0.2, final_top_k=5):\n",
    "    \"\"\"\n",
    "    Test all six approaches for a given query\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing Query: '{query}'\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. PRF Rerank\n",
    "    print(f\"\\n1. PRF RERANK:\")\n",
    "    results['prf_rerank'] = prf_dime.prf_rerank(\n",
    "        query, prf_k=prf_k, zero_out_ratio=zero_out_ratio, final_top_k=final_top_k\n",
    "    )\n",
    "    \n",
    "    # 2. PRF Refetch\n",
    "    print(f\"\\n2. PRF REFETCH:\")\n",
    "    results['prf_refetch'] = prf_dime.prf_refetch(\n",
    "        query, prf_k=prf_k, zero_out_ratio=zero_out_ratio, final_top_k=final_top_k\n",
    "    )\n",
    "    \n",
    "    # 3. LLM Rerank\n",
    "    print(f\"\\n3. LLM RERANK:\")\n",
    "    results['llm_rerank'] = llm_dime.llm_rerank(\n",
    "        query, zero_out_ratio=zero_out_ratio, final_top_k=final_top_k\n",
    "    )\n",
    "    \n",
    "    # 4. LLM Refetch\n",
    "    print(f\"\\n4. LLM REFETCH:\")\n",
    "    results['llm_refetch'] = llm_dime.llm_refetch(\n",
    "        query, zero_out_ratio=zero_out_ratio, final_top_k=final_top_k\n",
    "    )\n",
    "    \n",
    "    # 5. Magnitude Rerank\n",
    "    print(f\"\\n5. MAGNITUDE RERANK:\")\n",
    "    results['magnitude_rerank'] = magnitude_dime.magnitude_rerank(\n",
    "        query, zero_out_ratio=zero_out_ratio, final_top_k=final_top_k\n",
    "    )\n",
    "    \n",
    "    # 6. Magnitude Refetch\n",
    "    print(f\"\\n6. MAGNITUDE REFETCH:\")\n",
    "    results['magnitude_refetch'] = magnitude_dime.magnitude_refetch(\n",
    "        query, zero_out_ratio=zero_out_ratio, final_top_k=final_top_k\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def display_results(results):\n",
    "    \"\"\"\n",
    "    Display results for all approaches\n",
    "    \"\"\"\n",
    "    query = list(results.values())[0]['query']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESULTS COMPARISON FOR: '{query}'\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get baseline results (original)\n",
    "    baseline_results = results['prf_rerank']['original_results']\n",
    "    print(f\"\\nBASELINE (Original Dense Retrieval):\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, result in enumerate(baseline_results[:5], 1):\n",
    "        print(f\"{i}. {result['title']} - Score: {result['score']:.4f}\")\n",
    "    \n",
    "    # Show results for each approach\n",
    "    for method_name, method_results in results.items():\n",
    "        print(f\"\\n{method_name.upper().replace('_', ' ')}:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Get the appropriate results key\n",
    "        if 'reranked_results' in method_results:\n",
    "            final_results = method_results['reranked_results']\n",
    "            score_key = 'new_score'\n",
    "        else:\n",
    "            final_results = method_results['refetched_results']\n",
    "            score_key = 'score'\n",
    "        \n",
    "        for i, result in enumerate(final_results[:5], 1):\n",
    "            score = result[score_key]\n",
    "            print(f\"{i}. {result['title']} - Score: {score:.4f}\")\n",
    "        \n",
    "        # Show LLM doc if available\n",
    "        if 'llm_doc' in method_results:\n",
    "            print(f\"   LLM Doc: {method_results['llm_doc'][:100]}...\")\n",
    "\n",
    "# Test with sample queries\n",
    "test_queries = [\n",
    "    \"black dress shirt\",\n",
    "    \"blue jeans\",\n",
    "    \"white sneakers\",\n",
    "    \"red dress\",\n",
    "    \"casual t-shirt\",\n",
    "    \"winter coat\",\n",
    "    \"summer dress\",\n",
    "]\n",
    "\n",
    "# Run tests\n",
    "all_results = {}\n",
    "for query in test_queries:  # Test first 2 queries\n",
    "    all_results[query] = test_all_approaches(query)\n",
    "    display_results(all_results[query])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ad3d7",
   "metadata": {},
   "source": [
    "## 4. Analysis and Metrics\n",
    "\n",
    "Let's analyze the effectiveness of each approach by looking at score differences and result changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_approach_effectiveness(results):\n",
    "    \"\"\"\n",
    "    Analyze the effectiveness of each approach\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"APPROACH EFFECTIVENESS ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    query = list(results.values())[0]['query']\n",
    "    baseline_results = results['prf_rerank']['original_results']\n",
    "    baseline_ids = [r['product_id'] for r in baseline_results[:5]]\n",
    "    \n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"Baseline top-5 IDs: {baseline_ids}\")\n",
    "    \n",
    "    for method_name, method_results in results.items():\n",
    "        print(f\"\\n{method_name.upper().replace('_', ' ')}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Get final results\n",
    "        if 'reranked_results' in method_results:\n",
    "            final_results = method_results['reranked_results']\n",
    "            score_key = 'new_score'\n",
    "        else:\n",
    "            final_results = method_results['refetched_results']\n",
    "            score_key = 'score'\n",
    "        \n",
    "        final_ids = [r['product_id'] for r in final_results[:5]]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        overlap = len(set(baseline_ids) & set(final_ids))\n",
    "        changes = 5 - overlap\n",
    "        avg_score = np.mean([r[score_key] for r in final_results[:5]])\n",
    "        \n",
    "        print(f\"  • Top-5 IDs: {final_ids}\")\n",
    "        print(f\"  • Overlap with baseline: {overlap}/5\")\n",
    "        print(f\"  • Changes from baseline: {changes}/5\")\n",
    "        print(f\"  • Average score: {avg_score:.4f}\")\n",
    "        \n",
    "        # For rerank methods, show score improvements\n",
    "        if 'reranked_results' in method_results:\n",
    "            original_scores = [r['original_score'] for r in final_results[:5]]\n",
    "            new_scores = [r['new_score'] for r in final_results[:5]]\n",
    "            score_changes = [new - orig for new, orig in zip(new_scores, original_scores)]\n",
    "            print(f\"  • Score changes: {[f'{c:+.4f}' for c in score_changes]}\")\n",
    "\n",
    "def compare_query_embeddings(results):\n",
    "    \"\"\"\n",
    "    Compare how different approaches modify the query embeddings\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"QUERY EMBEDDING MODIFICATIONS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    query = list(results.values())[0]['query']\n",
    "    original_embedding = results['prf_rerank']['original_query_embedding']\n",
    "    \n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"Original embedding norm: {np.linalg.norm(original_embedding):.4f}\")\n",
    "    print(f\"Original embedding first 10 dims: {original_embedding[:10]}\")\n",
    "    \n",
    "    for method_name, method_results in results.items():\n",
    "        modified_embedding = method_results['modified_query_embedding']\n",
    "        \n",
    "        # Calculate metrics\n",
    "        norm_diff = np.linalg.norm(modified_embedding) - np.linalg.norm(original_embedding)\n",
    "        cosine_sim = np.dot(original_embedding, modified_embedding) / \\\n",
    "                    (np.linalg.norm(original_embedding) * np.linalg.norm(modified_embedding))\n",
    "        zero_dims = np.sum(modified_embedding == 0)\n",
    "        \n",
    "        print(f\"\\n{method_name.upper().replace('_', ' ')}:\")\n",
    "        print(f\"  • Modified norm: {np.linalg.norm(modified_embedding):.4f} (Δ: {norm_diff:+.4f})\")\n",
    "        print(f\"  • Cosine similarity with original: {cosine_sim:.4f}\")\n",
    "        print(f\"  • Zeroed dimensions: {zero_dims}/{len(modified_embedding)}\")\n",
    "        print(f\"  • Modified first 10 dims: {modified_embedding[:10]}\")\n",
    "\n",
    "# Analyze results for the first query\n",
    "if all_results:\n",
    "    first_query = list(all_results.keys())[0]\n",
    "    analyze_approach_effectiveness(all_results[first_query])\n",
    "    compare_query_embeddings(all_results[first_query])\n",
    "else:\n",
    "    print(\"Run the previous cell first to generate results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13afcf86",
   "metadata": {},
   "source": [
    "## 5. Parameter Experimentation\n",
    "\n",
    "Let's experiment with different parameters to understand their impact on retrieval performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_zero_out_ratios(query=\"black dress shirt\"):\n",
    "    \"\"\"\n",
    "    Experiment with different zero-out ratios\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ZERO-OUT RATIO EXPERIMENTATION\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    ratios = [0.0, 0.1, 0.2, 0.3, 0.5]\n",
    "    \n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    \n",
    "    for ratio in ratios:\n",
    "        print(f\"\\nZero-out ratio: {ratio} ({ratio*100}% dimensions zeroed)\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Test PRF rerank\n",
    "        prf_result = prf_dime.prf_rerank(query, zero_out_ratio=ratio, final_top_k=3)\n",
    "        prf_avg_score = np.mean([r['new_score'] for r in prf_result['reranked_results']])\n",
    "        \n",
    "        # Test LLM rerank  \n",
    "        llm_result = llm_dime.llm_rerank(query, zero_out_ratio=ratio, final_top_k=3)\n",
    "        llm_avg_score = np.mean([r['new_score'] for r in llm_result['reranked_results']])\n",
    "        \n",
    "        # Test Magnitude rerank\n",
    "        magnitude_result = magnitude_dime.magnitude_rerank(query, zero_out_ratio=ratio, final_top_k=3)\n",
    "        magnitude_avg_score = np.mean([r['new_score'] for r in magnitude_result['reranked_results']])\n",
    "        \n",
    "        print(f\"PRF Rerank avg score: {prf_avg_score:.4f}\")\n",
    "        print(f\"LLM Rerank avg score: {llm_avg_score:.4f}\")\n",
    "        print(f\"Magnitude Rerank avg score: {magnitude_avg_score:.4f}\")\n",
    "\n",
    "def experiment_prf_k_values(query=\"black dress shirt\"):\n",
    "    \"\"\"\n",
    "    Experiment with different PRF-k values\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PRF-K VALUE EXPERIMENTATION\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    prf_k_values = [3, 5, 10, 20]\n",
    "    \n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    \n",
    "    for k in prf_k_values:\n",
    "        print(f\"\\nPRF-k: {k}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Test both rerank and refetch\n",
    "        rerank_result = prf_dime.prf_rerank(query, prf_k=k, final_top_k=3)\n",
    "        refetch_result = prf_dime.prf_refetch(query, prf_k=k, final_top_k=3)\n",
    "        \n",
    "        rerank_avg = np.mean([r['new_score'] for r in rerank_result['reranked_results']])\n",
    "        refetch_avg = np.mean([r['score'] for r in refetch_result['refetched_results']])\n",
    "        \n",
    "        print(f\"PRF Rerank avg score: {rerank_avg:.4f}\")\n",
    "        print(f\"PRF Refetch avg score: {refetch_avg:.4f}\")\n",
    "\n",
    "def experiment_attention_types(query=\"black dress shirt\"):\n",
    "    \"\"\"\n",
    "    Experiment with different attention types for PRF\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ATTENTION TYPE EXPERIMENTATION\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    attention_types = [\"linear\", \"softmax\"]\n",
    "    temperatures = [0.5, 1.0, 2.0]\n",
    "    \n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    \n",
    "    for att_type in attention_types:\n",
    "        print(f\"\\nAttention type: {att_type}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        if att_type == \"linear\":\n",
    "            # Test unweighted vs weighted\n",
    "            for weighted in [False, True]:\n",
    "                result = prf_dime.prf_rerank(query, weighted=weighted, attention_type=att_type, final_top_k=3)\n",
    "                avg_score = np.mean([r['new_score'] for r in result['reranked_results']])\n",
    "                print(f\"  Weighted={weighted}: {avg_score:.4f}\")\n",
    "        else:\n",
    "            # Test different temperatures for softmax\n",
    "            for temp in temperatures:\n",
    "                result = prf_dime.prf_rerank(query, weighted=True, attention_type=att_type, \n",
    "                                           temperature=temp, final_top_k=3)\n",
    "                avg_score = np.mean([r['new_score'] for r in result['reranked_results']])\n",
    "                print(f\"  Temperature={temp}: {avg_score:.4f}\")\n",
    "\n",
    "# Run experiments\n",
    "experiment_zero_out_ratios()\n",
    "experiment_prf_k_values() \n",
    "experiment_attention_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56923eb",
   "metadata": {},
   "source": [
    "## 6. Conclusion and Next Steps\n",
    "\n",
    "This notebook implements the core DIME approaches:\n",
    "\n",
    "### Implemented Approaches:\n",
    "1. **PRF-based Rerank**: Uses PRF to compute centroids and re-scores existing results\n",
    "2. **PRF-based Refetch**: Uses PRF to compute centroids and performs new retrieval\n",
    "3. **LLM-based Rerank**: Uses LLM-generated docs to determine importance and re-scores\n",
    "4. **LLM-based Refetch**: Uses LLM-generated docs to determine importance and performs new retrieval\n",
    "5. **Magnitude-based Rerank**: Uses query magnitude to determine importance and re-scores\n",
    "6. **Magnitude-based Refetch**: Uses query magnitude to determine importance and performs new retrieval\n",
    "\n",
    "### Key Components:\n",
    "- **Dimension Importance Estimation**: \n",
    "  - PRF: Element-wise product between centroid and query\n",
    "  - LLM: Element-wise product between LLM-doc embedding and query  \n",
    "  - Magnitude: Absolute values of query dimensions |qi|\n",
    "- **Dimension Zeroing**: Zeros out least important dimensions based on importance scores\n",
    "- **Flexible Parameters**: Supports different zero-out ratios, PRF-k values, attention types\n",
    "\n",
    "### Next Steps:\n",
    "1. **Real LLM Integration**: Replace simulated LLM docs with actual LLM-generated content\n",
    "2. **Evaluation Metrics**: Add proper evaluation metrics (NDCG, MAP, etc.)\n",
    "3. **Hyperparameter Tuning**: Systematic optimization of parameters\n",
    "4. **Dataset Expansion**: Test on larger, more diverse datasets\n",
    "5. **Comparison with SOTA**: Compare against other dense retrieval methods\n",
    "\n",
    "The implementation is modular and extensible, making it easy to integrate the actual DIME methodology when ready."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
